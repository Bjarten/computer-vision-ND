{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the required modules for webacm\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import PIL.Image\n",
    "from io import BytesIO as StringIO\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet18_grayscale(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    (fc): Linear(in_features=512, out_features=136, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models import NaimishNet, resnet18_grayscale\n",
    "\n",
    "img_size = 224\n",
    "\n",
    "#net = NaimishNet(image_size=img_size, kernels=[5, 5, 5, 5], use_maxp=False)\n",
    "net = resnet18_grayscale()\n",
    "\n",
    "model_dir = 'saved_models/'\n",
    "model_name = 'resnet18_gray_epochs64_bs64_vloss0.00414.pt'\n",
    "\n",
    "net.load_state_dict(torch.load(model_dir+model_name))\n",
    "\n",
    "# print out net\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a haar cascade classifier for detecting frontal faces\n",
    "face_cascade = cv2.CascadeClassifier('detector_architectures/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(img):\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.2, 2)\n",
    "    \n",
    "    # make a copy of the original image to plot detections on\n",
    "    image_with_detections = img.copy()\n",
    "        \n",
    "    for (x,y,w,h) in faces:\n",
    "        # draw a rectangle around each detected face\n",
    "        # you may also need to change the width of the rectangle drawn depending on image resolution\n",
    "        cv2.rectangle(image_with_detections,(x,y),(x+w,y+h),(255,0,0), 3) \n",
    "\n",
    "    return image_with_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(cam):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    #flip image for natural viewing\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_keypoints(img, scale):\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.2, 2)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        return img\n",
    "    \n",
    "    image_copy = np.copy(img)\n",
    "    \n",
    "    # loop over the detected faces from your haar cascade\n",
    "    for (x,y,w,h) in faces:\n",
    "        \n",
    "        # don't scale ouside of the frame!\n",
    "        if (y-scale) < 0 and (x-scale) < 0:\n",
    "            if (y-scale) < (x-scale):\n",
    "                scale += (y-scale)\n",
    "            else:\n",
    "                scale += (x-scale)\n",
    "        elif (y-scale) < 0 :\n",
    "            scale += (y-scale)\n",
    "        elif (x-scale) < 0:\n",
    "            scale += (x-scale)\n",
    "\n",
    "        # Select the region of interest that is the face in the image \n",
    "        roi = image_copy[y-scale:y+h+scale, x-scale:x+w+scale]\n",
    "\n",
    "        roi_color = np.copy(roi)\n",
    "        \n",
    "        ## Convert the face region from RGB to grayscale\n",
    "        roi = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "        ## Normalize the grayscale image so that its color range falls in [0,1] instead of [0,255]\n",
    "        roi = roi/255.0\n",
    "        ## Rescale the detected face to be the expected square size for your CNN (224x224, suggested)\n",
    "        \n",
    "        h, w = roi.shape\n",
    "        \n",
    "        shape_before_resize = roi.shape\n",
    "        \n",
    "        roi = cv2.resize(roi, (img_size, img_size))\n",
    "        \n",
    "        shape_after_resize = roi.shape\n",
    "        \n",
    "        # how much the image was scaled with\n",
    "        # will use to resize and fit to the webcam image\n",
    "        scaling_factor = shape_before_resize[0]/shape_after_resize[0]\n",
    "        \n",
    "        roi_color = cv2.resize(roi_color, (img_size, img_size))\n",
    "        # Make copy for displaying keypoint over\n",
    "        roi_copy = np.copy(roi)\n",
    "        \n",
    "        ## Reshape the numpy image shape (H x W x C) into a torch image shape (C x H x W)\n",
    "        \n",
    "        # if image has no grayscale color channel, add one\n",
    "        if(len(roi.shape) == 2):\n",
    "            # add that third color dim\n",
    "            roi = roi.reshape(roi.shape[0], roi.shape[1], 1)\n",
    "        \n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        roi = roi.transpose((2, 0, 1))\n",
    "        \n",
    "        roi = torch.from_numpy(roi)\n",
    "        roi = roi.type(torch.FloatTensor)\n",
    "        \n",
    "        roi.unsqueeze_(0)\n",
    "        ## Make facial keypoint predictions using your loaded, trained network     \n",
    "        ## perform a forward pass to get the predicted facial keypoints\n",
    "        \n",
    "        # forward pass to get net output\n",
    "        output_pts = net(roi)\n",
    "        # reshape to size x 68 x 2 pts\n",
    "        output_pts = output_pts.view(68, -1)\n",
    "        \n",
    "        # undo normalization of keypoints\n",
    "        output_pts = output_pts.detach().numpy()   \n",
    "        output_pts = output_pts*(roi_copy.shape[0]/4)+roi_copy.shape[0]/2\n",
    "        for pts in output_pts:\n",
    "            pts[0] = x-scale+pts[0]*scaling_factor\n",
    "            pts[1] = y-scale+pts[1]*scaling_factor\n",
    "        \n",
    "        ## Draw mask\n",
    "       \n",
    "        color = (0,255,0)\n",
    "        \n",
    "        for i in range(len(output_pts)):\n",
    "            if (i != 16 and i != 21 and i != 26 and i != 30 and i != 35 and i < 68) :\n",
    "                pt1 = (output_pts[i][0], output_pts[i][1])\n",
    "                \n",
    "                if i == 17:\n",
    "                    # left eyebrow\n",
    "                    color = (0,100,0)\n",
    "                elif i == 22:\n",
    "                    # right eyebrow\n",
    "                    color = (0,100,0)\n",
    "                elif i == 27:\n",
    "                    # nose stem\n",
    "                    color = (255,255,0)\n",
    "                elif i == 31:\n",
    "                    # nose tip\n",
    "                    color = (255,255,0)\n",
    "                elif i == 36:\n",
    "                    # left eye\n",
    "                    color = (0,250,154)\n",
    "                elif i == 42:\n",
    "                    # right eye\n",
    "                    color = (0,250,154)\n",
    "                elif i == 48:\n",
    "                    # lips\n",
    "                    color = (255,20,147)\n",
    "                     \n",
    "                if i == 41:\n",
    "                    pt2 = (output_pts[36][0], output_pts[36][1])\n",
    "                elif i == 47:\n",
    "                    pt2 = (output_pts[42][0], output_pts[42][1])\n",
    "                elif i == 67:\n",
    "                    pt2 = (output_pts[60][0], output_pts[60][1])\n",
    "                else:\n",
    "                    pt2 = (output_pts[i+1][0], output_pts[i+1][1])\n",
    "                    \n",
    "                cv2.line(image_copy, pt1, pt2, color, thickness=5, lineType=8, shift=0) \n",
    "                \n",
    "        return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream stopped\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "save_video = True\n",
    "\n",
    "if save_video:\n",
    "    # https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "    # Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "    # We convert the resolutions from float to integer.\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    # Define the codec and create VideoWriter object.The output is stored in 'outpput.avi' file.\n",
    "    out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 4, (frame_width,frame_height))\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        #start_time = time.time()\n",
    "        \n",
    "        # Capture frame-by-frame\n",
    "        frame = get_frame(cap)\n",
    "\n",
    "        # Convert the image from OpenCV BGR format to matplotlib RGB format\n",
    "        # to display the image\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "        frame = detect_keypoints(frame, 30)\n",
    "        \n",
    "        # write to video file\n",
    "        if save_video:\n",
    "            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        showarray(frame)\n",
    "         \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "        #print(\"FPS: \", 1.0 / (time.time() - start_time)) # FPS = 1 / time to process loop\n",
    "\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    print(\"Stream stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wabcam code is based on the [displaying webcam video in IPython notebook](https://github.com/ktaletsk/NCCV/blob/master/Realtime_video_ipython.ipynb) project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
